{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926f4832-7089-4882-be21-e0e0e57e12b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d30a9f-99e6-4e85-a3c7-2bef1f69ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"full_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857aaa10-e597-42fd-b06c-b7a0eefa5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca5edc3-f825-4747-969a-e463167ebd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "x = data['text']\n",
    "y = data['label']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf30121-91d6-40f6-b984-f6fba74142a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x_train_vectorized = vectorizer.fit_transform(x_train)\n",
    "x_test_vectorized = vectorizer.transform(x_test)\n",
    "\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49513d8d-bcab-4c70-adfb-0231319890f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9566732412886259\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(x_train_vectorized, y_train)\n",
    "\n",
    "pred_lr = LR.predict(x_test_vectorized)\n",
    "\n",
    "print(LR.score(x_test_vectorized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25952335-d0bc-4eb0-ae4c-da3e830edb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT = DecisionTreeClassifier()\n",
    "# DT.fit(x_train_vectorized, y_train)\n",
    "\n",
    "# pred_dt = DT.predict(x_test_vectorized)\n",
    "\n",
    "# print(DT.score(x_test_vectorized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5943d58-2af7-4a9b-a692-3825677b5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB = GradientBoostingClassifier(random_state = 0)\n",
    "# GB.fit(x_train_vectorized, y_train)\n",
    "\n",
    "# pred_gb = GB.predict(x_test_vectorized)\n",
    "\n",
    "# print(GB.score(x_test_vectorized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12218b7f-12e8-4548-9beb-1dd26f27d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF = RandomForestClassifier(random_state = 0)\n",
    "# RF.fit(x_train_vectorized, y_train)\n",
    "\n",
    "# pred_rf = RF.predict(x_test_vectorized)\n",
    "\n",
    "# print(RF.score(x_test_vectorized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4441f04e-a2cf-4058-a429-f0472c1b5766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(LR, 'lr_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ffd338-c4d9-4725-be0a-d2badeff687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_lable(n):\n",
    "    if n==0:\n",
    "        return \"Not a Fake News\"\n",
    "    elif n==1:\n",
    "        return \"Fake News\"\n",
    "    \n",
    "def manual_testing(news):\n",
    "    testing_news = {\"text\":[news]}\n",
    "    new_def_test = pd.DataFrame(testing_news)\n",
    "    new_def_test['text'] = new_def_test[\"text\"].apply(preprocess_text)\n",
    "    new_x_test = new_def_test[\"text\"]\n",
    "    new_xv_test = vectorizer.transform(new_x_test)\n",
    "    pred_LR = LR.predict(new_xv_test)\n",
    "    pred_LR_proba = LR.predict_proba(new_xv_test)\n",
    "    \n",
    "    confidence = max(pred_LR_proba[0])\n",
    "    \n",
    "    print(\n",
    "        f\"\"\"\n",
    "        LR prediction: {output_lable(pred_LR[0])}\n",
    "        Confidence: {confidence * 100:.2f}%\n",
    "        \"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16cbd9c3-3f44-4b44-890b-85dc194b4e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        LR prediction: Not a Fake News\n",
      "        Confidence: 55.90%\n",
      "        \n",
      "\n",
      "        LR prediction: Fake News\n",
      "        Confidence: 85.07%\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "with open(\"test_true.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_true = f.read()\n",
    "\n",
    "with open(\"test_fake.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_fake = f.read()\n",
    "    \n",
    "manual_testing(text_true)\n",
    "manual_testing(text_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e338562-a286-4c42-9e91-290b65d50d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
